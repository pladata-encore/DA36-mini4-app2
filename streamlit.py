import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv
import os

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# OpenAI API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = openai_api_key


# OpenAI ëª¨ë¸ ì´ˆê¸°í™”
model = ChatOpenAI(model="gpt-4o", temperature=0)

# ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ì„¤ì •
vectorstore_paths = {
    "ê²½ë§ˆì •ë³´": r"C:\Workspace\DA36_mini4_ma\min\vectors_new\vs_race_guide",
    "ê²½ì£¼ì¼ì •": r"C:\Workspace\DA36_mini4_ma\min\vectors_new\vs_schedule",
    "ìš°ìŠ¹ë§ˆê¸°ë¡": r"C:\Workspace\DA36_mini4_ma\min\vectors_new\vs_winners",
    "ê²½ì£¼ë§ˆì •ë³´": r"C:\Workspace\DA36_mini4_ma\min\vectors_new\vs_horse_info"
}


# ì§ˆë¬¸ ë¶„ë¥˜ í•¨ìˆ˜
def classify_question(query):
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="""\
    You are an expert in horse racing. Your task is to classify the given user question into one of the following categories:

    - ê²½ë§ˆì •ë³´: Questions about general information such as rules, betting methods, and terminology.
    - ê²½ì£¼ì¼ì •: Questions about race schedules, dates, times, or locations. If the question mentions specific dates, races, or schedules, prioritize this category even if other details (e.g., horse performance) are included.
    - ìš°ìŠ¹ë§ˆê¸°ë¡: Questions about winning horses and their records.
    - ê²½ì£¼ë§ˆì •ë³´: Questions about specific horses, their participation counts, rankings, or performance metrics.

    If the question does not match any category, return "Unknown".
    """),
        HumanMessage(content=f"User Question: {query}\n\nClassify this question into one of the categories:")
    ])

    output_parser = StrOutputParser()
    chain = prompt | model | output_parser
    response = chain.invoke({})

    return response.strip('-')


# ì§ˆë¬¸ ìš”ì•½ í•¨ìˆ˜
def summarize_query(query):
    if len(query.split()) <= 20:
        return False, query

    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="You are an assistant that summarizes questions into concise queries for search."),
        HumanMessage(content=f"Original question: {query}\n\nSummarize this into a concise query:")
    ])
    summarized_query = (prompt | model | StrOutputParser()).invoke({"query": query})
    print("âš ï¸ì§ˆë¬¸ì´ 20ë‹¨ì–´ë¥¼ ì´ˆê³¼í•˜ì—¬ ìš”ì•½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True, summarized_query


# ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def rag_and_prompt(query):
    category = classify_question(query)

    vectorstore_path = vectorstore_paths[category]
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
    vector_store = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)
    retriever = vector_store.as_retriever()

    is_summarized, summarized_query = summarize_query(query)  # ìš”ì•½ ìˆ˜í–‰
    if is_summarized:
        print(f"- ê¸°ì¡´ ì§ˆë¬¸: {query}\n- ìš”ì•½ëœ ì§ˆë¬¸: {summarized_query}\n")
    else:
        print(f"ì§ˆë¬¸: {query}\n")

    results = retriever.get_relevant_documents(summarized_query)

    retrieved_data = "\n".join([doc.page_content for doc in results])

    # prompt = ChatPromptTemplate.from_messages([
    #     SystemMessage(content="""\
    #     ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì• êµê°€ ë§ì€ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
    #     ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ì£¼ ìƒì„¸í•˜ê³  ì¬ë¯¸ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    #     ì˜ˆì‹œ: 2024ë…„ 12ì›” 21ì¼ ì„œìš¸ ê²½ì£¼ ì¼ì •ì„ ë¬¼ì–´ë³´ë©´, ê²½ì£¼ì˜ ì‹œê°„ê³¼, ìµœê·¼ ì„±ì ì´ ì¢‹ì€ ë§ì˜ ì •ë³´ ë“±ì„ ì•Œë ¤ì¤˜ì•¼ í•©ë‹ˆë‹¤.
    #     """),
    #     HumanMessage(content=f"""\
    #     ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— contextë§Œì„ ì´ìš©í•´ ë‹µë³€í•´ ì£¼ì„¸ìš”.
    #     ì§ˆë¬¸: {query}
    #     context: {retrieved_data}
    #     """)
    # ])

    # **ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬**
    conversation_history = "\n".join(
        [f"ğŸ‘¤ ì‚¬ìš©ì: {msg['content']}" if msg["role"] == "user" else f"ğŸ¤– ì±—ë´‡: {msg['content']}"
         for msg in st.session_state.messages]
    )

    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="""\
            ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì• êµê°€ ë§ì€ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤. 
            ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ì£¼ ìƒì„¸í•˜ê³  ì¬ë¯¸ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
            ì˜ˆì‹œ: 2024ë…„ 12ì›” 21ì¼ ì„œìš¸ ê²½ì£¼ ì¼ì •ì„ ë¬¼ì–´ë³´ë©´, ê²½ì£¼ì˜ ì‹œê°„ê³¼, ìµœê·¼ ì„±ì ì´ ì¢‹ì€ ë§ì˜ ì •ë³´ ë“±ì„ ì•Œë ¤ì¤˜ì•¼ í•©ë‹ˆë‹¤.
            """),
        HumanMessage(content=f"""
            ëŒ€í™” ê¸°ë¡:
            {conversation_history}
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            ê²€ìƒ‰ëœ ì •ë³´:
            {retrieved_data}
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì¬ë¯¸ìˆëŠ” ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
            ê²€ìƒ‰ëœ ì •ë³´ë§Œì„ ì´ìš©í•´ ë‹µë³€í•´ ì£¼ì„¸ìš”.
            """)
    ])

    output_parser = StrOutputParser()
    chain = prompt | model | output_parser
    response = chain.invoke({"query": query})
    return response

# Streamlit ì•± ì‹œì‘
main_bg_color = "#CEF6CE"
st.markdown(f"""
        <style>
        /* ë©”ì¸ í˜ì´ì§€ ë°°ê²½ ìƒ‰ ì„¤ì • */
        .stApp {{
            background-color: {main_bg_color};
        }}
        </style>
        """, unsafe_allow_html=True)


# st.title("ğŸ‡ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡")
# st.write("ì•ˆë…•í•˜ì„¸ìš”! ê²½ë§ˆ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ë„ì™€ë“œë¦´ê²Œìš”. ğŸ˜Š")
#
# # **ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”**
# if "messages" not in st.session_state:
#     st.session_state.messages = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
#
# # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
#
# if st.button("ì§ˆë¬¸í•˜ê¸°"):
#     if user_input:
#         st.session_state.messages.append({"role": "user", "content": user_input})
#         answer = rag_and_prompt(user_input)
#         st.session_state.messages.append({"role": "assistant", "content": answer})
#
# st.write("ğŸ”–ëŒ€í™” ê¸°ë¡:")
# for msg in st.session_state.messages:
#     if msg["role"] == "user":
#         st.write(f"ğŸ¼ ë¯¼í•˜: {msg['content']}")
#     else:
#         st.write(f"-`,é¦¬ËÂ´-: {msg['content']}")


# st.title("ğŸ‡ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡ MA!")
# st.write("í™˜ì˜í•©ë‹ˆë‹¤! ê²½ë§ˆì— ê´€í•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ë³´ì„¸ìš”. ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦´ê²Œìš”! ğŸ˜Š")
# st.divider()
#
# # **ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”**
# if "messages" not in st.session_state:
#     st.session_state.messages = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
#
# st.write("ğŸ”–ëŒ€í™” ê¸°ë¡:")
# for msg in st.session_state.messages:
#     if msg["role"] == "user":
#         st.write(f"ğŸ¼ ë¯¼í•˜: {msg['content']}")
#     else:
#         st.write(f"-`,é¦¬ËÂ´-: {msg['content']}")
#
# # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
# if st.button("ê¶ê¸ˆí•´ìš”"):
#     if user_input:
#         st.session_state.messages.append({"role": "user", "content": user_input})
#         answer = rag_and_prompt(user_input)
#         st.session_state.messages.append({"role": "assistant", "content": answer})

#
# st.title("ğŸ‡ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡ MA!")
# st.write("í™˜ì˜í•©ë‹ˆë‹¤! ê²½ë§ˆì— ê´€í•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ë³´ì„¸ìš”. ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦´ê²Œìš”! ğŸ˜Š")
# st.divider()
#
# # **ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”**
# if "messages" not in st.session_state:
#     st.session_state.messages = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
#
# st.write("ğŸ”– ëŒ€í™” ê¸°ë¡:")
# for i, msg in enumerate(st.session_state.messages):
#     if msg["role"] == "user":
#         st.write(f"ğŸ¼ ë¯¼í•˜: {msg['content']}")
#     else:
#         st.write(f"-`,é¦¬ËÂ´-â•: {msg['content']}")
#     # êµ¬ë¶„ì„ ì€ ë‹µë³€ ì´í›„ì—ë§Œ ì¶”ê°€
#     if i < len(st.session_state.messages) - 1 and st.session_state.messages[i + 1]["role"] != msg["role"]:
#         st.divider()
#
# # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
# if st.button("ê¶ê¸ˆí•´ìš”"):
#     if user_input:
#         st.session_state.messages.append({"role": "user", "content": user_input})
#         answer = rag_and_prompt(user_input)
#         st.session_state.messages.append({"role": "assistant", "content": answer})


# import streamlit as st
#
# st.title("ğŸ‡ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡ MA!")
# st.write("í™˜ì˜í•©ë‹ˆë‹¤! ê²½ë§ˆì— ê´€í•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ë³´ì„¸ìš”. ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦´ê²Œìš”! ğŸ˜Š")
# st.divider()
#
# # **ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”**
# if "messages" not in st.session_state:
#     st.session_state.messages = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
#
# st.write("ğŸ”– ëŒ€í™” ê¸°ë¡:")
# # ë©”ì‹œì§€ë¥¼ ìŒìœ¼ë¡œ ë¬¶ì–´ì„œ ì¶œë ¥
# pairs = []
# for i in range(0, len(st.session_state.messages), 2):
#     user_msg = st.session_state.messages[i]
#     assistant_msg = st.session_state.messages[i + 1] if i + 1 < len(st.session_state.messages) else None
#     pairs.append((user_msg, assistant_msg))
#
# for user_msg, assistant_msg in pairs:
#     st.write(f"ğŸ¼ ë¯¼í•˜: {user_msg['content']}")
#     if assistant_msg:
#         st.write(f"-`,é¦¬ËÂ´-â•: {assistant_msg['content']}")
#     st.divider()  # ê° ì§ˆë¬¸-ë‹µë³€ ìŒ ë’¤ì— êµ¬ë¶„ì„  ì¶”ê°€
#
# # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
# if st.button("ê¶ê¸ˆí•´ìš”"):
#     if user_input:
#         st.session_state.messages.append({"role": "user", "content": user_input})
#
#         # ì§ˆë¬¸ ìš”ì•½ ìˆ˜í–‰
#         is_summarized, summarized_query = summarize_query(user_input)
#         if is_summarized:
#             st.write("âš ï¸ ì§ˆë¬¸ì´ ê¸¸ì–´ ìš”ì•½ë˜ì—ˆìŠµë‹ˆë‹¤. ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ ìš”ì•½ëœ ì§ˆë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
#
#         # RAG ë° ë‹µë³€ ìƒì„±
#         answer = rag_and_prompt(summarized_query)
#         st.session_state.messages.append({"role": "assistant", "content": answer})


import streamlit as st

import streamlit as st

st.title("ğŸ‡ ê²½ë§ˆ ì•ˆë‚´ ì±—ë´‡ MA!")
st.write("í™˜ì˜í•©ë‹ˆë‹¤! ê²½ë§ˆì— ê´€í•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ë³´ì„¸ìš”. ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦´ê²Œìš”! ğŸ˜Š")
st.divider()

# **ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”**
if "messages" not in st.session_state:
    st.session_state.messages = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”

# **ì§ˆë¬¸ ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”**
if "current_question" not in st.session_state:
    st.session_state.current_question = ""

st.write("ğŸ”– ëŒ€í™” ê¸°ë¡:")
# ë©”ì‹œì§€ë¥¼ ìŒìœ¼ë¡œ ë¬¶ì–´ì„œ ì¶œë ¥
pairs = []
for i in range(0, len(st.session_state.messages), 2):
    user_msg = st.session_state.messages[i]
    assistant_msg = st.session_state.messages[i + 1] if i + 1 < len(st.session_state.messages) else None
    pairs.append((user_msg, assistant_msg))

for user_msg, assistant_msg in pairs:
    st.write(f"ğŸ¼ ë¯¼í•˜: {user_msg['content']}")
    if assistant_msg:
        st.write(f"-`,é¦¬ËÂ´-â•: {assistant_msg['content']}")
    st.divider()  # ê° ì§ˆë¬¸-ë‹µë³€ ìŒ ë’¤ì— êµ¬ë¶„ì„  ì¶”ê°€

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", value=st.session_state.current_question)

if st.button("ê¶ê¸ˆí•´ìš”"):
    if user_input.strip():
        # í˜„ì¬ ì§ˆë¬¸ ì €ì¥
        st.session_state.current_question = user_input.strip()
        st.session_state.messages.append({"role": "user", "content": user_input})

        # ì§ˆë¬¸ ìš”ì•½ ìˆ˜í–‰
        is_summarized, summarized_query = summarize_query(user_input)
        if is_summarized:
            st.write("âš ï¸ ì§ˆë¬¸ì´ ê¸¸ì–´ ìš”ì•½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            summarized_query = user_input

        # RAG ë° ë‹µë³€ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            answer = rag_and_prompt(summarized_query)
            st.session_state.messages.append({"role": "assistant", "content": answer})

        # UIì— ìš”ì•½ëœ ì§ˆë¬¸ê³¼ ë‹µë³€ ë°”ë¡œ ì¶œë ¥
        st.write(f"ğŸ¼ ë¯¼í•˜: {user_input}")
        if is_summarized:
            st.write(f"ğŸ” ìš”ì•½ëœ ì§ˆë¬¸: {summarized_query}")
        st.write(f"-`,é¦¬ËÂ´-â•: {answer}")
        st.divider()

        # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
        st.session_state.current_question = ""
