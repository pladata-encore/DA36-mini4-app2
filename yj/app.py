import streamlit as st
from streamlit_chat import message as msg
import openai
import speech_recognition as sr
from PIL import Image
import base64
from io import BytesIO
from dotenv import load_dotenv
import os

# .env íŒŒì¼ì—ì„œ API í‚¤ ì½ê¸°
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ ë§ˆ! ì±—ë´‡",
    page_icon="ğŸ¨",
    layout="wide",
)

# ë°°ê²½ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì„¤ì •
background_image = st.file_uploader("ë°°ê²½ ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"])

def get_image_base64(image):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

if background_image is not None:
    img = Image.open(background_image)
    bg_base64 = get_image_base64(img)
    st.markdown(
        f"""
        <style>
        body {{
            background-image: url('data:image/png;base64,{bg_base64}');
            background-size: cover;
            background-repeat: no-repeat;
            background-attachment: fixed;
        }}
        .stButton > button {{
            background-color: #007BFF;
            color: white;
            border-radius: 5px;
            padding: 10px;
        }}
        .stTextInput > div > input {{
            border: 2px solid #007BFF;
            border-radius: 5px;
        }}
        .chat-container {{
            border: 2px solid #007BFF;
            border-radius: 10px;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.9); /* ì¹ íŒì²˜ëŸ¼ ë³´ì´ê²Œ */
            max-height: 500px;
            overflow-y: scroll;
            margin-bottom: 20px;
        }}
        .chat-board {{
            border: 5px solid #222222;
            border-radius: 15px;
            padding: 10px;
            background-color: #222222;
            color: white;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# ì œëª©ê³¼ ì„¤ëª…
st.title("ğŸ ë§ˆ! ì±—ë´‡!")
st.write("ì¹œì ˆí•˜ê³  ìœ ìš©í•œ ëŒ€ë‹µì„ ì œê³µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")

# ëŒ€í™” ì„¹ì…˜
st.subheader("ëŒ€í™”í•˜ê¸°")
with st.container():
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)

    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
        ]

    # ì¹ íŒì²˜ëŸ¼ êµ¬ë¶„ëœ ëŒ€í™”ì°½
    st.markdown('<div class="chat-board">', unsafe_allow_html=True)
    for i, message in enumerate(st.session_state["messages"]):
        if message["role"] == "user":
            msg(message["content"], is_user=True, key=f"user_{i}")
        else:
            msg(message["content"], is_user=False, key=f"assistant_{i}")
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

# ìŒì„± ì…ë ¥ ê¸°ëŠ¥
recognizer = sr.Recognizer()
microphone = sr.Microphone()

if st.button("ìŒì„± ì…ë ¥ ì‹œì‘"):
    with microphone as source:
        st.write("ìŒì„±ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
        audio = recognizer.listen(source)
        try:
            user_input = recognizer.recognize_google(audio, language="ko-KR")
            st.write(f"ìŒì„±ìœ¼ë¡œ ì…ë ¥ëœ ë‚´ìš©: {user_input}")
            st.session_state["messages"].append({"role": "user", "content": user_input})
        except sr.UnknownValueError:
            st.write("ìŒì„±ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        except sr.RequestError:
            st.write("ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

# í…ìŠ¤íŠ¸ ì…ë ¥
user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", "")
if st.button("ì§ˆë¬¸í•˜ê¸°"):
    st.session_state["messages"].append({"role": "user", "content": user_input})

    # OpenAI API í˜¸ì¶œ
    if user_input:
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=user_input,
            max_tokens=150
        )
        assistant_response = response.choices[0].text.strip()
        st.session_state["messages"].append({"role": "assistant", "content": assistant_response})

st.markdown("---")
st.info("Streamlit ì•±ì„ ì‹¤í–‰í•˜ë ¤ë©´, `streamlit run app.py` ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
